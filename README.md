# ğŸ Python & SQL Mini Project Assignment

This repository contains the completed tasks from a Python & SQL assignment, showcasing data engineering, cleaning, and querying skills using Python (Pandas) and SQL.

## ğŸ“ Project Structure

python-sql-assignment/
â”‚
â”œâ”€â”€ etl_pipeline/
â”‚   â”œâ”€â”€ etl_pipeline.ipynb
â”‚   â”œâ”€â”€ cleaned_reviews_output.xls
â”‚   â””â”€â”€ cleaned_reviews_output.json
â”‚
â”œâ”€â”€ data_deduplication/
â”‚   â”œâ”€â”€ data_deduplication.ipynb
â”‚   â””â”€â”€ deduplicated_users.xls
â”‚
â”œâ”€â”€ sql_queries/
â”‚   â”œâ”€â”€ data_joins_filtering.sql
â”‚   â””â”€â”€ identify_missing_hourly_readings.sql
â”‚
â”œâ”€â”€ vip_customers_analysis/
â”‚   â”œâ”€â”€ purchases.csv
â”‚   â”œâ”€â”€ members.csv
â”‚   â”œâ”€â”€ vip_customers_query.sql
â”‚   â””â”€â”€ vip_customers_analysis.ipynb
â”‚
â””â”€â”€ README.md


---

## ğŸ”„ Task 1: ETL Pipeline Simulation

**Objective**: Build a basic ETL pipeline for product reviews.

- **Extract**: Load reviews from a CSV.
- **Transform**:
  - Remove rows with null ratings or reviews.
  - Ensure ratings are integers within the 1â€“5 range.
  - Extract simple sentiment: mark as "Negative" if "bad" is in the review text, else "Positive".
- **Load**: Save the cleaned and enriched dataset to a CSV or JSON(Optional) file.

ğŸ”§ Implemented in: [`etl_pipeline/etl_pipeline.ipynb`](https://github.com/manishdevdi/python-sql-assignment/blob/main/etl_pipeline/etl_pipeline.ipynb
)

---

## ğŸ” Task 2: Data Deduplication

**Objective**: Remove duplicate user records based on email while keeping the latest entry.

- Use `last_updated` to retain the most recent record.

ğŸ”§ Implemented in: [`data_deduplication/data_deduplication.ipynb`](https://github.com/manishdevdi/python-sql-assignment/blob/main/data_deduplication/data_deduplication.ipynb)

---

## ğŸ§¾ Task 3: SQL - Data Joins and Filtering

**Objective**: Retrieve users with more than 3 orders in the last 90 days and calculate their total spend.

ğŸ—ƒï¸ SQL logic used:
- `INNER JOIN`
- `GROUP BY`
- `HAVING`

ğŸ“„ See: [`sql_queries/data_joins_filtering.sql`](https://github.com/manishdevdi/python-sql-assignment/blob/main/sql_queries/data_joins_filtering.sql)

---

## â±ï¸ Task 4: SQL - Identify Data Gaps

**Objective**: Identify missing hourly sensor readings over the past 24 hours for each sensor.

ğŸ“„ See: [`sql_queries/identify_missing_hourly_readings.sql`](https://github.com/manishdevdi/python-sql-assignment/blob/main/sql_queries/identify_missing_hourly_readings.sql)

---

## ğŸŒŸ Bonus Task: VIP Customer Identification

### Objective:
Find Gold members who have spent over $250 across all transactions.

### Approach:

- **SQL**: Join `purchases` and `members`, group by customer, and filter.
- **Python**: Merge two CSVs with Pandas, group by customer, and apply filters.

ğŸ§  Logic:
- `INNER JOIN`, `SUM(amount)`, `GROUP BY`, and `HAVING` in SQL.
- `pandas.merge()`, `groupby()`, and filtering in Python.

ğŸ“ Python: [`vip_customers_analysis/vip_customers_analysis.ipynb`](https://github.com/manishdevdi/python-sql-assignment/blob/main/vip_customers_analysis/vip_customers_analysis.ipynb)   
ğŸ“„ SQL: [`vip_customers_analysis/vip_customers_query.sql`](https://github.com/manishdevdi/python-sql-assignment/blob/main/vip_customers_analysis/vip_customers_query.sql)

---

## âœ… Tools & Libraries

- Python 3.x
- Pandas
- SQL (MySQL / PostgreSQL dialect)

---

## ğŸ“¬ Contact

Made with â¤ï¸ by **Manish Devdi**  
ğŸ“§ [manishdevdi778@gmail.com](mailto:manishdevdi778@gmail.com)  
ğŸŒ [LinkedIn â€“ Manish Devdi](https://www.linkedin.com/in/manish-devdi/)

---

## ğŸ“Œ License

This project is open-source and available under the [MIT License](https://github.com/manishdevdi/python-sql-assignment/blob/main/License).
